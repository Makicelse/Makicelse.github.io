---
title: python迷你项目学习
date: 2024-05-17 22:12:00 +0800
categories: [计算机学习]
tags: [计算机学习, Python]
---

> 基于Python课老师布置的作业题目の学习存档。  
{: .prompt-tip }

## 一、统计中文文本词频，生成词云图

- 参考文章： 

  [理论与实战：一篇看懂Python词云 - 牛牛巴士社区](https://www.nnbs.cc/d/10721)  
  [wordcloud：自定义背景图片，生成词云-阿里云开发者社区](https://developer.aliyun.com/article/884811)  
  [Python中jieba库和wordcloud词云库配合使用进阶，生成指定形状和颜色的词云图 - 知乎](https://zhuanlan.zhihu.com/p/671460122)   

- 用到的库/模块：  

  - `jieba`：中文文本分割  
  - `from collections import Counter`：统计词频  
  - `numpy`、`from PIL import Image`：对我们自己导入的背景图进行处理  
  - `from wordcloud import WordCloud, ImageColorGenerator`：生成词云图    

- 大致步骤：

  1. 文件读取（加上 `encoding='utf-8'` ），将要分析的文本 & 停用词各自读取到一个 str 中；  
  2. 用 `jieba.cut()`  分割，得到初步词表；  
  3. 去除停用词（包括标点、空格），将剩余的词汇加入新 list 中，得到最终词表；  
  4. 用 `Counter()` 统计词频后，将 list 转换为 dict ；  
  5. 加载背景图后，用 `numpy.array()` 预处理背景图，然后用 `ImageColorGenerator()` 提取图片颜色；  
  6. 用 `WordCloud()` （记得在参数中指定上一步中提取的颜色 ）生成词云对象，并用 `.generate_from_frequencies()` 根据词频 dict 生成词云；  
  7. 最后用 `.to_file()` 生成词云图片。  

- 代码：    

```python
# 使用 conda install 的话，要在管理员终端中下载

from os import path
# 中文文本分词
import jieba
# 词频统计
from collections import Counter
# 生成词云
from wordcloud import WordCloud, ImageColorGenerator
# 图片处理
# imageio.imread('cat.jpg')
import numpy as np
# import matplotlib.pyplot as plt
# 相比上面的库，图像处理功能更强大
from PIL import Image

# 设置基本路径
d = path.dirname(__file__)
# 设置停用词表路径
stopword_path = path.join(d, 'stop_words_zh.txt')
# 读取停用词表
# Return a list of the lines in the string, breaking at line boundaries
with open(stopword_path, 'r', encoding='utf-8') as stopword_f:
    stopword_list = stopword_f.read().splitlines()
# 设置要分析的文本路径
text_path = path.join(d, '杀人十角馆.txt')
# 读取文本
with open(text_path, 'r', encoding='utf-8') as text_f:
    text = text_f.read()
# seg_list暂存jieba.cut初步分割后的词表
seg_list = jieba.cut(text, cut_all=False, HMM=True)
liststr = '/'.join(seg_list)

# 去除标点和停用词
wordlist = []
for i in liststr.split('/'):
    # 去除文字前后空格
    word = i.strip()
    # 符合条件的词语加入列表（停用词表还是漏了很多词，不管了）
    if not(word in stopword_list) and len(word)>1:
        wordlist.append(word)
# 去停用词后，将列表转换为词频字典
frequency = dict(Counter(wordlist))

# 加载背景图
background_image = np.array(Image.open(path.join(d, 'image.jpg')))
# 提取图片颜色，设置词云颜色
bg_color = ImageColorGenerator(background_image, default_color=None)
# 生成词云
wc = WordCloud(
    # 背景颜色
    background_color='white', 
    # 背景图片
    mask=background_image, 
    # 中文汉字显示
    font_path='C:\Windows\Fonts\simhei.ttf', 
    # 最大词数
    max_words=500, 
    # 自定义颜色后记得在参数中指定
    color_func=bg_color
    )
# 根据词频生成词云
wc.generate_from_frequencies(frequency)
# 生成图片
wc.to_file('output.png')

```

- 最终词云图：  
  - （因为停用词表和文本不太搭，去除效果不佳）  

![output](https://cdn.jsdelivr.net/gh/Makicelse/image/img/study/202405180057504.png){: width="500" height="707" }



## 二、电影推荐系统（协同过滤算法）

- 参考文章：  

  [协同过滤算法概述与python 实现协同过滤算法基于内容](https://blog.csdn.net/HHTNAN/article/details/79854525)   
  [协同过滤（cf）——usr-item和item-item介绍原创](https://blog.csdn.net/liuxiao723846/article/details/88321097)    
  **`DataFrame`对象数据去重：**[pandas: Get unique values and their counts in a column](https://note.nkmk.me/en/python-pandas-value-counts/)  
  **`ndarray`数组连接：**[NumPy: Concatenate arrays with np.concatenate, np.stack, etc.](https://note.nkmk.me/en/python-numpy-concatenate-stack-block/)    
  
- 用到的库/模块：  

  - `sklearn`：高阶算法  
  - `pandas`：数据分析（提供了数据结构 `DataFrame` 和 `Series` ）   
  - `numpy`：数组、矩阵处理（提供了多维数组对象 `ndarray` ）  
  
- 名词解释： 
  
  - **user - item/ user - base：**对比用户间喜好的相似性。根据与目标用户喜好相似的用户，向目标用户推荐与其最相似用户的喜好物品。  
  - **item - item/ item - base：**综合不同用户对不同物品的评分，向目标用户推荐与其喜好相似的物品。  
  - 相似度计算：  
    - **欧式距离法（euclidean 系数法）**  
    - **p系数法（pearson 系数法）**  
  
- 大致步骤（我也不是很清楚）：  
  
  1. 定要素——确定参与偏好相似评价的各个要素；  
  2. 读数据——用 `pandas.read_csv()`， 将用户评分数据读取到 `DataFrame` 对象中；   
  3. 数据处理——将 `DataFrame` 数据集转化为矩阵；  
  4. 计算相似度——确定相似度计算方法，求出两两主体之间的相似度，并存储为相似度矩阵；
     - 以欧式距离法为例：用 `sklearn.…….pairwise_distances()` 计算两向量间距离；之后将距离转化为相似度，分别创建用户相似度矩阵 & 电影相似度矩阵      
  5. 加权度——基于相似度和评价度量，为每个主体未评价过的对象计算推荐指数；  
     - 若采用 item - item 模式，则“剩余用户 sim * 各电影评分 = 各电影最终权重”    
  6. 输出最终预测结果。  
  
- 代码：  

  ```python
  import os
  import numpy
  import pandas
  from sklearn import model_selection
  from sklearn.metrics.pairwise import pairwise_distances
  
  
  # 欧氏距离转化为相似度
  
  def dis_to_sim(rating_matrix):
      for x in range(len(rating_matrix)):
          for y in range(len(rating_matrix[x])):
              rating_matrix[x][y] = 1 / (1 + rating_matrix[x][y])
      return rating_matrix
  
  # 两种预测模式
  
  def predict(user_id, ratings, similarity, type='user'):
      pred = 0
  
      if type == 'item':
          
          weight_matrix = numpy.zeros_like(ratings)
          
          # 剩余用户 sim * 各电影评分 = 各电影权重
          for r in range(len(ratings)):
              for s in range(len(similarity[user_id-1])):
                  weight_matrix[r][s] = ratings[r][s] * similarity[user_id-1][s]
                  
          # 对同一电影的所有用户权重：求和、取平均权重，即为该电影最终权重
          # 计算沿指定轴 axis 的算术平均值，返回含指定轴平均值的 numpy 数组: axis=0为沿行，axis=1为沿列
          mean_weight = weight_matrix.mean(axis=1)
          
          
          # 排除目标用户看过的（即用户评过分的）电影
          movie_No = numpy.argmax(mean_weight)
          for i in range(len(mean_weight)):
              if ratings[user_id-1][movie_No] != 0:
                  break
              numpy.delete(mean_weight, movie_No)
              movie_No = numpy.argmax(mean_weight)
              
          # 返回权重最高的电影の序号（即 numpy 数组下标加一）
          pred = movie_No + 1
  
      elif type == 'user':
          
          # 对用户相似度矩阵排序后，取相似度最大的人（除开自己！于是使用切片 & 拼接）
          # 拼接 numpy 数组：https://stackoverflow.com/questions/9236926/concatenating-two-one-dimensional-numpy-arrays
          similar_user_array = numpy.concatenate((similarity[user_id-1][:user_id-2], similarity[user_id-1][user_id:]), axis=0)
          similar_user = numpy.argmax(similar_user_array)
          
          
          # 推荐相似的人看过 and 目标分析用户没看过的电影序号
          movie_No = numpy.argmax(ratings[similar_user])
          for i in range(len(ratings[similar_user])):
              if ratings[similar_user][movie_No] != 0 and ratings[user_id-1][movie_No] == 0:
                  break
              numpy.delete(ratings[similar_user], movie_No)
              movie_No = numpy.argmax(ratings[similar_user])
              
          # 返回权重最高的电影の序号（即 numpy 数组下标加一）
          pred = movie_No + 1
          
          
      return pred
  
  
  # 输入用户 id 
  
  user_id = int(input('输入用户id：'))
  
  # 生成训练、评估数据集
  
  file_path = os.path.join('ml-100k', 'u.data')
  # 自定义列名
  headers = ['user_id', 'movie_id', 'rating', 'timestamp']
  # Read a comma-separated values (csv) file into DataFrame.
  df = pandas.read_csv(filepath_or_buffer=file_path, 
                       sep='\t', names=headers)
  
  # 统计用户 & 电影总数，创建 user-item 矩阵时使用
  
  # 若数据集中包含 N/A 则使用 .nunique() 较佳
  n_users = df.user_id.unique().shape[0]
  n_movies = df.movie_id.unique().shape[0]
  
  # 将 df 数据集转化为 user-item 矩阵
  
  rating_matrix = numpy.zeros((n_users, n_movies))
  # Iterate over DataFrame rows as namedtuples.
  for line in df.itertuples():
      rating_matrix[line[1]-1, line[2]-1] = line[3]
      
  
  # 计算相似度，构造相似度矩阵：采用欧式距离
  
  # 此方法采用向量数组或距离矩阵，并返回距离矩阵。
  user_distance = pairwise_distances(rating_matrix, metric='euclidean')
  # 在 NumPy 中，矩阵对象有一个 .T 属性，用于返回矩阵的转置。
  movie_distance = pairwise_distances(rating_matrix.T, metric='euclidean')
  # 距离转换为相似度：加一取倒
  user_sim = dis_to_sim(user_distance)
  movie_sim = dis_to_sim(movie_distance)
  
  
  # 预测
  
  # 根据（用户）对电影的评分推荐相似电影
  item_prediction = predict(user_id, rating_matrix, movie_sim, type='item')
  # 根据相似用户推荐电影
  user_prediction = predict(user_id, rating_matrix, user_sim, type='user')
  
  # 将电影序号和电影名对应为字典；使用.split('|')分割数据
  
  movie_dict = {}
  # 编码问题：https://stackoverflow.com/questions/19699367/for-line-in-results-in-unicodedecodeerror-utf-8-codec-cant-decode-byte
  with open(os.path.join('ml-100k', 'u.item'), 'r', encoding='ISO-8859-1') as info_f:
      info_list = info_f.readlines()
      for str in info_list[:]:
          fields = str.split('|')
          movie_id = int(fields[0])
          movie_title = (fields[1])
          # 添加字典元素
          movie_dict[movie_id] = movie_title
  
  # 输出推荐结果
  print('为你推荐: ')
  print('猜你喜欢电影：《{}》'.format(movie_dict[item_prediction]))
  print('和你类似的用户也喜欢电影:《{}》'.format(movie_dict[user_prediction]))
  
  ```

  


## 三、Python游戏版块

### pgzero (pygame zero)  

### pygame  

#### 基础：

- 图片绘制—— surface 对象、Rect 对象  

- 文字显示：

  用法示例：

  ```python
  # 显示文字の字体
  info_font = pygame.font.SysFont('arial', 30)
  text = info_font.render('Choose your Servant', True, WHITE)
  rec_text = text.get_rect(); rec_text.center = (400, 100)
  screen.blit(text, rec_text)
  ```

  [What fonts can I use with pygame.font.Font? - Stack Overflow](https://stackoverflow.com/questions/38001898/what-fonts-can-i-use-with-pygame-font-font)    

- 碰撞检测：Rect 对象  

  [python - How do I detect collision in pygame? - Stack Overflow](https://stackoverflow.com/questions/29640685/how-do-i-detect-collision-in-pygame)  

- 时间延迟：设置两个变量，使用时间差  

  - 获得时间：`Clock对象.get_time()`  

    用法示例：  

    ```python
    clock = pygame.time.Clock()  
    # 老问题：边界用大于等于，而非直接等于  
    if self.spawn_timer >= 50000:  
        self.new_enemy()  
        # 计数器置0  
        self.spawn_timer = 0   
    self.spawn_timer += clock.get_time()  
    ```

- 背景音乐 & 音效 

  - 背景音乐类：`pygame.mixer.music`  
  - 音效类：`pygame.mixer.Sound`

#### 进阶（伪）——类封装：

- 入门认知：  

  Program Arcade Games With Python And Pygame：http://programarcadegames.com/index.php?chapter=introduction_to_classes&lang=en  
  [Pygame Platformer Tutorial - Full Course - YouTube](https://www.youtube.com/watch?v=2gABYM5M0ww)（太长了，先只看看大佬的代码风格）  

- 代码参考：github各路仓库    

  [matsrorbecker/pgzero_game: A simplified version of Space Invaders ...](https://github.com/matsrorbecker/pgzero_game)  

### pyxel  
