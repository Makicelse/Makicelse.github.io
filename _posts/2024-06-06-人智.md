---
title: IDMB情感分类
date: 2024-06-08 00:10:00 +0800
categories:  [计算机学习]
tags: [计算机学习, 人工智能]
---

## 基于规则の推理系统

##### 产生式系统

- 由专家手动制定规则，机器根据这些规则进行推理和预测。  

缺陷：人工制定规则能力有限，规则库更新速度赶不上当今知识迭代速度。  

## 基于统计の分类模型

### 常见模型

##### 朴素贝叶斯

- `sklearn.naive_bayes.MultinomialNB()`

##### 逻辑回归

- `sklearn.linear_model.LogisticRegression()`

##### 支持向量机 (SVM)

##### 随机森林

### 分类模型评估指标

参考文章：  
[【火炉炼AI】机器学习011-分类模型的评估：准确率，精确率，召回率，F1值](https://github.com/RayDean/MachineLearning/blob/master/Articles/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0011-%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0-%E7%B2%BE%E7%A1%AE%E7%8E%87%EF%BC%8C%E5%8F%AC%E5%9B%9E%E7%8E%87%EF%BC%8CF%E5%80%BC.md)  
[https://juejin.cn/post/6844903470756167688](https://juejin.cn/post/6844903470756167688)  

- 假设样本分为黑 & 白两类：黑为 Positive 类，白为 Negative 类。

- 模型预测分类后，会有四种类型的样本。用混淆矩阵表示：

| 黑为 Positive 类 |        实际：黑        |        实际：白        |
| :--------------: | :--------------------: | :--------------------: |
| **机器判断：黑** | True Positive（正确）  | False Positive（错误） |
| **机器判断：白** | False Negative（错误） | True Negative（正确）  |



- 四项评估指标

1. **准确率（Accuracy）**： 模型预测正确的样本在所有样本中的比例。
2. **精确率（Precision）**：**模型预测为 Positive 的样本中**实际为 Positive 的比例。
3. **召回率（Recall）**：**实际为 Positive 的样本中**被模型正确预测为 Positive 类的比例。 
4. **F1分数（F1 Score）**： F1分数是精确率和召回率的调和平均数，用于**衡量模型在不平衡数据集上的表现**。

搞懂了含义之后，结合混淆矩阵对比四个指标，模型性能表现一目了然。

- `sklearn.metrics.classification_report()`

## 特征工程

> 网上的步骤没个统一标准，本文只对实验中学习涉及的步骤进行笔记，其余步骤日后再说。
{: .prompt-info }  

### 特征生成：创造、改进特征

#### 词频特征

- 词袋法（BoW）

  - 不考虑文法、语义以及词的顺序，统计每个词在文档中出现的频率。  

  例如，对于两个文档 "I love machine learning" 和 "Machine learning is fun"，词袋法可以将其表示为如下的词频矩阵：

  |           | I    | love | machine | learning | is   | fun  |
  | --------- | ---- | ---- | ------- | -------- | ---- | ---- |
  | **文档1** | 1    | 1    | 1       | 1        | 0    | 0    |
  | **文档2** | 0    | 0    | 1       | 1        | 1    | 1    |

  - `sklearn.feature_extraction.text.CountVectorizer(stop_words)`
- TF-IDF

  - `sklearn.feature_extraction.text.TfidfVectorizer()`


#### 词向量特征

- 词向量

> 在自然语言处理 (NLP) 中，**词向量**是单词的一种表示形式。该表示形式用于文本分析。  
>
> 通常，该表示形式是一个实值向量，它以这样的方式对单词的含义进行编码，即向量空间中距离较近的单词的含义应该相似。可以使用语言建模和特征学习技术获得词向量，其中词汇表中的单词或短语被映射到实数向量。  
>
> 生成这种映射的方法包括神经网络、词语共现矩阵的降维、概率模型 、可解释的知识库方法 ，以及根据词语出现的上下文的明确表示。——维基百科  

和 BoW 基于统计方法构建词频特征矩阵不同，Word2Vec 使用神经网络架构来生成词嵌入。

神经网络（辅助理解词嵌入法，此处不细展开）：[Neural Network Simply Explained \| Deep Learning Tutorial 4 (Tensorflow2.0, Keras & Python](https://youtu.be/ER2It2mIagI?si=2LTC9sNcJqCNEyV6)



##### 词嵌入方法 (word embedding)

将词语映射到低维连续向量空间，以捕捉词语之间的语义关系。

[chap-语言模型与词嵌入.pdf](https://nndl.github.io/old-chap/chap-语言模型与词嵌入.pdf)  

- ~~[One-Hot Encoding](https://www.geeksforgeeks.org/ml-one-hot-encoding/)~~
  
- Word2Vec
  
  [What is Word2Vec? A Simple Explanation | Deep Learning Tutorial 41 (Tensorflow, Keras & Python)](https://youtu.be/hQwFeIupNP0?si=9z6MbQsxwk-iPI8V)  
  
  - CBoW (Continuous Bag of Words)：通过上下文预测目标词。  
  - Skip-gram：通过目标词预测上下文。
  
- Glove

- FastText



### 特征选择：选择最有用的特征

特征选择器：`sklearn.feature_selection.SelectKBest(score_func=特征评分函数, k=前k个最优特征)`    

- 常用特征评分函数：
  - 卡方检验（`chi2`）
  - F值分类（ANOVA F值，`f_classif`）  
  - 互信息分类（`mutual_info_classif`）  
  - F值回归（`f_regression`）
  - 互信息回归（`mutual_info_regression`）